{"cells":[{"cell_type":"code","source":["# Imports\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import MinMaxScaler\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import ast\n","import matplotlib.pyplot as plt\n","from google.colab import drive\n","import os\n","import logging\n","import pickle"],"metadata":{"id":"0FnEemH2PEAe","executionInfo":{"status":"ok","timestamp":1746564167525,"user_tz":-330,"elapsed":12801,"user":{"displayName":"kittu","userId":"09666691421238000801"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# Initialisation\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Define paths\n","data_path = '/content/drive/MyDrive/smai_project/dataset/dataset20/'\n","output_path = '/content/drive/MyDrive/smai_project/output_graphs/'\n","model_path = '/content/drive/MyDrive/smai_project/model/model20/'\n","log_file_path = os.path.join(output_path, 'train.log')\n","\n","# Create output and model directories if they don't exist\n","for path in [output_path, model_path]:\n","  if not os.path.exists(path):\n","    os.makedirs(path)\n","\n","# Set up logging\n","logging.basicConfig( level=logging.INFO, format='%(asctime)s - %(message)s', handlers=[ logging.FileHandler(log_file_path), logging.StreamHandler() ] )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jKfihAuHPdwJ","outputId":"b20bbf27-1243-41a2-90ee-c58fd432caa2","executionInfo":{"status":"ok","timestamp":1746564229694,"user_tz":-330,"elapsed":62174,"user":{"displayName":"kittu","userId":"09666691421238000801"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"g_hy7WN4PBtA","executionInfo":{"status":"ok","timestamp":1746564229705,"user_tz":-330,"elapsed":6,"user":{"displayName":"kittu","userId":"09666691421238000801"}}},"source":["# Feature Extraction Function\n","def extract_sequence_features(df):\n","    \"\"\"Extract features from ball and player sequences.\"\"\"\n","    def get_shooter_position(ball_seq, players_seq, personId):\n","        shooter_x, shooter_y = None, None\n","        if players_seq and isinstance(players_seq, list) and len(players_seq) > 0:\n","            first_frame = players_seq[0] if isinstance(players_seq[0], list) else players_seq\n","            if first_frame and isinstance(first_frame, list):\n","                for player in first_frame:\n","                    if len(player) != 5:\n","                        continue\n","                    _, player_id, x, y, _ = player\n","                    if player_id == personId:\n","                        shooter_x, shooter_y = x, y\n","                        break\n","\n","        if shooter_x is None or shooter_y is None:\n","            if not ball_seq or not isinstance(ball_seq, list) or len(ball_seq) == 0:\n","                return 0, 0\n","            first_pos = ball_seq[0]\n","            if not isinstance(first_pos, list) or len(first_pos) != 3:\n","                return 0, 0\n","            shooter_x, shooter_y, _ = first_pos\n","        return shooter_x, shooter_y\n","\n","    df['shooter_x'], df['shooter_y'] = zip(*df.apply(\n","        lambda row: get_shooter_position(row['ball_seq'], row['players_seq'], row['personId']), axis=1\n","    ))\n","\n","    df['initial_height'] = df['ball_seq'].apply(lambda seq: seq[0][2] if len(seq) > 0 and len(seq[0]) == 3 else 0)\n","    df['max_height'] = df['ball_seq'].apply(lambda seq: max([point[2] for point in seq]) if len(seq) > 0 and all(len(point) == 3 for point in seq) else 0)\n","    df['traj_length'] = df['ball_seq'].apply(len)\n","    df['shotDistance'] = df.apply(\n","        lambda row: np.sqrt((row['shooter_x'] - row['basket_x'])**2 + (row['shooter_y'] - row['basket_y'])**2), axis=1\n","    )\n","    df['shotDistance'] = df['shotDistance'].replace(0, 1)\n","    df['traj_curvature'] = df['max_height'] / df['shotDistance']\n","\n","    df['release_angle'] = df.apply(\n","        lambda row: np.arctan2(row['shooter_y'] - row['basket_y'], row['shooter_x'] - row['basket_x']), axis=1\n","    )\n","\n","    def calculate_defender_proximity(shooter_x, shooter_y, players_seq):\n","        min_distance = float('inf')\n","        shooter_team_id = None\n","\n","        if not players_seq or not isinstance(players_seq, list) or len(players_seq) == 0:\n","            return 0\n","\n","        first_frame = players_seq[0] if isinstance(players_seq[0], list) else players_seq\n","        if not first_frame or not isinstance(first_frame, list):\n","            return 0\n","\n","        closest_player_distance = float('inf')\n","        for player in first_frame:\n","            if len(player) != 5:\n","                continue\n","            team_id, _, x, y, _ = player\n","            distance = np.sqrt((shooter_x - x)**2 + (shooter_y - y)**2)\n","            if distance < closest_player_distance:\n","                closest_player_distance = distance\n","                shooter_team_id = team_id\n","\n","        if shooter_team_id is None:\n","            logging.warning(f\"Could not determine shooter team for position ({shooter_x}, {shooter_y})\")\n","            return 0\n","\n","        for player in first_frame:\n","            if len(player) != 5:\n","                continue\n","            team_id, _, x, y, _ = player\n","            if team_id == shooter_team_id:\n","                continue\n","            distance = np.sqrt((shooter_x - x)**2 + (shooter_y - y)**2)\n","            min_distance = min(min_distance, distance)\n","        return min_distance if min_distance != float('inf') else 0\n","\n","    df['defender_proximity'] = df.apply(\n","        lambda row: calculate_defender_proximity(row['shooter_x'], row['shooter_y'], row['players_seq']), axis=1\n","    )\n","\n","    def extract_player_positions(players_seq, shooter_x, shooter_y):\n","        shooter_team_id = None\n","        teammates = []\n","        defenders = []\n","\n","        if not players_seq or not isinstance(players_seq, list) or len(players_seq) == 0:\n","            return [0, 0, 0, 0]\n","\n","        first_frame = players_seq[0] if isinstance(players_seq[0], list) else players_seq\n","        if not first_frame or not isinstance(first_frame, list):\n","            return [0, 0, 0, 0]\n","\n","        closest_player_distance = float('inf')\n","        for player in first_frame:\n","            if len(player) != 5:\n","                continue\n","            team_id, _, x, y, _ = player\n","            distance = np.sqrt((shooter_x - x)**2 + (shooter_y - y)**2)\n","            if distance < closest_player_distance:\n","                closest_player_distance = distance\n","                shooter_team_id = team_id\n","\n","        if shooter_team_id is None:\n","            logging.warning(f\"Could not determine shooter team for position ({shooter_x}, {shooter_y})\")\n","            return [0, 0, 0, 0]\n","\n","        for player in first_frame:\n","            if len(player) != 5:\n","                continue\n","            team_id, _, x, y, _ = player\n","            if team_id == shooter_team_id:\n","                teammates.append([x, y])\n","            else:\n","                defenders.append([x, y])\n","\n","        closest_teammate = [0, 0]\n","        if teammates:\n","            teammate_distances = [(np.sqrt((shooter_x - tx)**2 + (shooter_y - ty)**2), tx, ty) for tx, ty in teammates]\n","            teammate_distances.sort()\n","            closest_teammate = [teammate_distances[1][1], teammate_distances[1][2]] if len(teammate_distances) > 1 else teammate_distances[0][1:3]\n","\n","        closest_defender = [0, 0]\n","        if defenders:\n","            defender_distances = [(np.sqrt((shooter_x - dx)**2 + (shooter_y - dy)**2), dx, dy) for dx, dy in defenders]\n","            defender_distances.sort()\n","            closest_defender = [defender_distances[0][1], defender_distances[0][2]]\n","\n","        return closest_teammate + closest_defender\n","\n","    df[['teammate_x', 'teammate_y', 'defender_x', 'defender_y']] = df.apply(\n","        lambda row: extract_player_positions(row['players_seq'], row['shooter_x'], row['shooter_y']), axis=1, result_type='expand'\n","    )\n","\n","    def extract_ball_dynamics(ball_seq):\n","        if not ball_seq or len(ball_seq) < 3:\n","            return [0, 0, 0, 0, 0, 0]\n","\n","        velocities = []\n","        for i in range(1, len(ball_seq)):\n","            if len(ball_seq[i]) != 3 or len(ball_seq[i-1]) != 3:\n","                continue\n","            dx = ball_seq[i][0] - ball_seq[i-1][0]\n","            dy = ball_seq[i][1] - ball_seq[i-1][1]\n","            dz = ball_seq[i][2] - ball_seq[i-1][2]\n","            velocities.append([dx, dy, dz])\n","\n","        if not velocities:\n","            return [0, 0, 0, 0, 0, 0]\n","\n","        accelerations = []\n","        for i in range(1, len(velocities)):\n","            ax = velocities[i][0] - velocities[i-1][0]\n","            ay = velocities[i][1] - velocities[i-1][1]\n","            az = velocities[i][2] - velocities[i-1][2]\n","            accelerations.append([ax, ay, az])\n","\n","        if not accelerations:\n","            avg_vel_x = np.mean([v[0] for v in velocities])\n","            avg_vel_y = np.mean([v[1] for v in velocities])\n","            avg_vel_z = np.mean([v[2] for v in velocities])\n","            return [avg_vel_x, avg_vel_y, avg_vel_z, 0, 0, 0]\n","\n","        avg_vel_x = np.mean([v[0] for v in velocities])\n","        avg_vel_y = np.mean([v[1] for v in velocities])\n","        avg_vel_z = np.mean([v[2] for v in velocities])\n","        avg_acc_x = np.mean([a[0] for a in accelerations])\n","        avg_acc_y = np.mean([a[1] for a in accelerations])\n","        avg_acc_z = np.mean([a[2] for a in accelerations])\n","\n","        return [avg_vel_x, avg_vel_y, avg_vel_z, avg_acc_x, avg_acc_y, avg_acc_z]\n","\n","    df[['avg_vel_x', 'avg_vel_y', 'avg_vel_z', 'avg_acc_x', 'avg_acc_y', 'avg_acc_z']] = df['ball_seq'].apply(\n","        lambda seq: extract_ball_dynamics(seq)\n","    ).apply(pd.Series)\n","\n","    def extract_shot_arc(ball_seq, basket_x, basket_y):\n","        if not ball_seq or len(ball_seq) < 3:\n","            return [0, 0]\n","\n","        try:\n","            release_x, release_y, release_z = ball_seq[0]\n","            peak_idx = max(range(len(ball_seq)), key=lambda i: ball_seq[i][2] if len(ball_seq[i]) == 3 else 0)\n","            peak_x, peak_y, peak_z = ball_seq[peak_idx]\n","\n","            last_valid_idx = -1\n","            for i in range(len(ball_seq)-1, 0, -1):\n","                if len(ball_seq[i]) == 3:\n","                    last_valid_idx = i\n","                    break\n","\n","            if last_valid_idx <= 0:\n","                return [0, 0]\n","\n","            p2 = ball_seq[last_valid_idx]\n","            p1 = ball_seq[max(0, last_valid_idx-1)]\n","\n","            if len(p1) != 3 or len(p2) != 3:\n","                return [0, 0]\n","\n","            horizontal_dist = np.sqrt((p2[0] - p1[0])**2 + (p2[1] - p1[1])**2)\n","            entry_angle = 90 if horizontal_dist == 0 else np.degrees(np.arctan2(p2[2] - p1[2], horizontal_dist))\n","\n","            total_dist = np.sqrt((basket_x - release_x)**2 + (basket_y - release_y)**2)\n","            arc_height_ratio = 0 if total_dist == 0 else peak_z / total_dist\n","\n","            return [entry_angle, arc_height_ratio]\n","        except Exception as e:\n","            logging.error(f\"Error extracting shot arc: {e}\")\n","            return [0, 0]\n","\n","    df[['entry_angle', 'arc_height_ratio']] = df.apply(\n","        lambda row: extract_shot_arc(row['ball_seq'], row['basket_x'], row['basket_y']),\n","        axis=1, result_type='expand'\n","    )\n","\n","    return df\n","\n","# Sequence Processing Function\n","def process_ball_sequences(df):\n","    \"\"\"Process ball sequences for LSTM input.\"\"\"\n","    sequences = []\n","    labels = []\n","\n","    for _, row in df.iterrows():\n","        ball_seq = row['ball_seq']\n","        result = row['shotResult']\n","\n","        if len(ball_seq) > 37:\n","            ball_seq = ball_seq[:37]\n","        elif len(ball_seq) < 37:\n","            last_pos = ball_seq[-1] if ball_seq else [0, 0, 0]\n","            while len(ball_seq) < 37:\n","                ball_seq.append(last_pos)\n","\n","        sequence = []\n","        for moment in ball_seq:\n","            if isinstance(moment, list) and len(moment) == 3:\n","                sequence.append(moment)\n","            else:\n","                sequence.append([0, 0, 0])\n","\n","        sequences.append(sequence)\n","        labels.append(result)\n","\n","    return np.array(sequences), np.array(labels)"],"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"id":"EhZJQmCjPBtB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f322bcb8-1393-4f60-f5cd-a2e28899c8d6","executionInfo":{"status":"ok","timestamp":1746564307025,"user_tz":-330,"elapsed":77321,"user":{"displayName":"kittu","userId":"09666691421238000801"}}},"source":["# Load and preprocess data\n","print(\"Loading datasets...\")\n","train_df = pd.read_csv(data_path + 'train.csv')\n","val_df = pd.read_csv(data_path + 'val.csv')\n","test_df = pd.read_csv(data_path + 'test.csv')\n","\n","# Parse sequences\n","for df in [train_df, val_df, test_df]:\n","    df['players_seq'] = df['players_seq'].apply(ast.literal_eval)\n","    df['ball_seq'] = df['ball_seq'].apply(ast.literal_eval)\n","\n","# Filter shots and encode labels\n","for df in [train_df, val_df, test_df]:\n","    df.drop(df[~df['shotResult'].isin(['Made Shot', 'Missed Shot'])].index, inplace=True)\n","    df['shotResult'] = df['shotResult'].map({'Made Shot': 1, 'Missed Shot': 0})\n","\n","# Extract features\n","print(\"Extracting features...\")\n","train_df = extract_sequence_features(train_df)\n","val_df = extract_sequence_features(val_df)\n","test_df = extract_sequence_features(test_df)\n","\n","# Define static features\n","static_features = [\n","    'shooter_x', 'shooter_y', 'release_angle', 'initial_height', 'max_height',\n","    'traj_length', 'traj_curvature', 'defender_proximity',\n","    'teammate_x', 'teammate_y', 'defender_x', 'defender_y',\n","    'avg_vel_x', 'avg_vel_y', 'avg_vel_z', 'avg_acc_x', 'avg_acc_y', 'avg_acc_z',\n","    'entry_angle', 'arc_height_ratio'\n","]\n","\n","# Clean up NaN or inf values\n","for df in [train_df, val_df, test_df]:\n","    df[static_features] = df[static_features].replace([np.inf, -np.inf], 0).fillna(0)\n","\n","# Process ball sequences\n","print(\"Processing ball sequences...\")\n","X_train_ball, y_train = process_ball_sequences(train_df)\n","X_val_ball, y_val = process_ball_sequences(val_df)\n","X_test_ball, y_test = process_ball_sequences(test_df)\n","\n","# Reshape for LSTM\n","X_train_ball = X_train_ball.reshape(X_train_ball.shape[0], 37, 3)\n","X_val_ball = X_val_ball.reshape(X_val_ball.shape[0], 37, 3)\n","X_test_ball = X_test_ball.reshape(X_test_ball.shape[0], 37, 3)\n","\n","# Normalize ball sequences\n","scaler_ball = MinMaxScaler()\n","X_train_ball_2d = X_train_ball.reshape(-1, 3)\n","X_train_ball_2d = scaler_ball.fit_transform(X_train_ball_2d)\n","X_train_ball = X_train_ball_2d.reshape(X_train_ball.shape)\n","\n","X_val_ball_2d = X_val_ball.reshape(-1, 3)\n","X_val_ball_2d = scaler_ball.transform(X_val_ball_2d)\n","X_val_ball = X_val_ball_2d.reshape(X_val_ball.shape)\n","\n","X_test_ball_2d = X_test_ball.reshape(-1, 3)\n","X_test_ball_2d = scaler_ball.transform(X_test_ball_2d)\n","X_test_ball = X_test_ball_2d.reshape(X_test_ball.shape)\n","\n","# Process static features\n","X_train_static = train_df[static_features].values\n","X_val_static = val_df[static_features].values\n","X_test_static = test_df[static_features].values\n","\n","# Normalize static features\n","scaler_static = MinMaxScaler()\n","X_train_static = scaler_static.fit_transform(X_train_static)\n","X_val_static = scaler_static.transform(X_val_static)\n","X_test_static = scaler_static.transform(X_test_static)"],"outputs":[{"output_type":"stream","name":"stdout","text":["Loading datasets...\n","Extracting features...\n","Processing ball sequences...\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"id":"tWaa7x6_PBtB","executionInfo":{"status":"ok","timestamp":1746564307135,"user_tz":-330,"elapsed":108,"user":{"displayName":"kittu","userId":"09666691421238000801"}}},"source":["# Define PyTorch Dataset\n","class ShotDataset(Dataset):\n","    \"\"\"Custom Dataset for basketball shot data.\"\"\"\n","    def __init__(self, ball_sequences, static_features, labels):\n","        self.ball_sequences = torch.tensor(ball_sequences, dtype=torch.float32)\n","        self.static_features = torch.tensor(static_features, dtype=torch.float32)\n","        self.labels = torch.tensor(labels, dtype=torch.float32)\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        return self.ball_sequences[idx], self.static_features[idx], self.labels[idx]\n","\n","# Define PyTorch Model\n","class ShotPredictor(nn.Module):\n","    \"\"\"PyTorch model for basketball shot prediction.\"\"\"\n","    def __init__(self, ball_input_size=3, static_input_size=20, hidden_size=64):\n","        super(ShotPredictor, self).__init__()\n","        self.lstm1 = nn.LSTM(ball_input_size, hidden_size, batch_first=True)\n","        self.dropout1 = nn.Dropout(0.2)\n","        self.lstm2 = nn.LSTM(hidden_size, hidden_size // 2, batch_first=True)\n","        self.dropout2 = nn.Dropout(0.2)\n","\n","        self.static_fc1 = nn.Linear(static_input_size, 32)\n","        self.static_relu = nn.ReLU()\n","        self.static_dropout = nn.Dropout(0.2)\n","\n","        self.fc_combined = nn.Linear(hidden_size // 2 + 32, 32)\n","        self.relu_combined = nn.ReLU()\n","        self.dropout_combined = nn.Dropout(0.2)\n","        self.fc_out = nn.Linear(32, 1)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, ball_seq, static_features):\n","        # Ball sequence processing\n","        lstm_out, _ = self.lstm1(ball_seq)\n","        lstm_out = self.dropout1(lstm_out)\n","        lstm_out, _ = self.lstm2(lstm_out)\n","        lstm_out = self.dropout2(lstm_out)\n","        lstm_out = lstm_out[:, -1, :]  # Take the last time step\n","\n","        # Static features processing\n","        static_out = self.static_fc1(static_features)\n","        static_out = self.static_relu(static_out)\n","        static_out = self.static_dropout(static_out)\n","\n","        # Combine\n","        combined = torch.cat((lstm_out, static_out), dim=1)\n","        out = self.fc_combined(combined)\n","        out = self.relu_combined(out)\n","        out = self.dropout_combined(out)\n","        out = self.fc_out(out)\n","        out = self.sigmoid(out)\n","        return out\n","\n","# Create datasets\n","train_dataset = ShotDataset(X_train_ball, X_train_static, y_train)\n","val_dataset = ShotDataset(X_val_ball, X_val_static, y_val)\n","test_dataset = ShotDataset(X_test_ball, X_test_static, y_test)\n","\n","# Create data loaders\n","batch_size = 32\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"],"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JJk6ZZ99PBtC","outputId":"eb70fe16-f8b0-456f-b2f6-4fb60ef05873","executionInfo":{"status":"ok","timestamp":1746564330798,"user_tz":-330,"elapsed":23660,"user":{"displayName":"kittu","userId":"09666691421238000801"}}},"source":["# Initialize model, loss, and optimizer\n","print(\"Building model...\")\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = ShotPredictor(ball_input_size=3, static_input_size=len(static_features)).to(device)\n","criterion = nn.BCELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Training loop\n","print(\"Training model...\")\n","num_epochs = 20\n","train_losses = []\n","val_losses = []\n","train_accuracies = []\n","val_accuracies = []\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    for ball_seq, static_features, labels in train_loader:\n","        ball_seq, static_features, labels = ball_seq.to(device), static_features.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(ball_seq, static_features).squeeze()\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * ball_seq.size(0)\n","        predicted = (outputs > 0.5).float()\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    epoch_loss = running_loss / len(train_dataset)\n","    epoch_acc = correct / total\n","    train_losses.append(epoch_loss)\n","    train_accuracies.append(epoch_acc)\n","\n","    # Validation\n","    model.eval()\n","    val_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for ball_seq, static_features, labels in val_loader:\n","            ball_seq, static_features, labels = ball_seq.to(device), static_features.to(device), labels.to(device)\n","            outputs = model(ball_seq, static_features).squeeze()\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item() * ball_seq.size(0)\n","            predicted = (outputs > 0.5).float()\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    val_loss = val_loss / len(val_dataset)\n","    val_acc = correct / total\n","    val_losses.append(val_loss)\n","    val_accuracies.append(val_acc)\n","\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n","\n","# Plot and save training metrics\n","plt.figure(figsize=(10, 5))\n","plt.plot(train_accuracies, label='Training Accuracy')\n","plt.plot(val_accuracies, label='Validation Accuracy')\n","plt.title('Training and Validation Accuracy Over Epochs')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.grid(True)\n","plt.savefig(os.path.join(output_path, 'accuracy_over_epochs.png'))\n","plt.close()\n","\n","plt.figure(figsize=(10, 5))\n","plt.plot(train_losses, label='Training Loss')\n","plt.plot(val_losses, label='Validation Loss')\n","plt.title('Training and Validation Loss Over Epochs')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.grid(True)\n","plt.savefig(os.path.join(output_path, 'loss_over_epochs.png'))\n","plt.close()\n","\n","# Save model and scalers\n","print(\"Saving model and scalers...\")\n","torch.save(model.state_dict(), os.path.join(model_path, 'shot_model.pth'))\n","with open(os.path.join(model_path, 'scaler_ball.pkl'), 'wb') as f:\n","    pickle.dump(scaler_ball, f)\n","with open(os.path.join(model_path, 'scaler_static.pkl'), 'wb') as f:\n","    pickle.dump(scaler_static, f)\n","\n","print(\"Training completed!\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["Building model...\n","Training model...\n","Epoch [1/20], Train Loss: 0.6652, Train Acc: 0.5905, Val Loss: 0.6244, Val Acc: 0.6759\n","Epoch [2/20], Train Loss: 0.6001, Train Acc: 0.6957, Val Loss: 0.5799, Val Acc: 0.7101\n","Epoch [3/20], Train Loss: 0.5548, Train Acc: 0.7268, Val Loss: 0.5466, Val Acc: 0.7357\n","Epoch [4/20], Train Loss: 0.5334, Train Acc: 0.7378, Val Loss: 0.5759, Val Acc: 0.6939\n","Epoch [5/20], Train Loss: 0.5306, Train Acc: 0.7342, Val Loss: 0.4986, Val Acc: 0.7519\n","Epoch [6/20], Train Loss: 0.5102, Train Acc: 0.7474, Val Loss: 0.4997, Val Acc: 0.7576\n","Epoch [7/20], Train Loss: 0.5166, Train Acc: 0.7433, Val Loss: 0.5069, Val Acc: 0.7481\n","Epoch [8/20], Train Loss: 0.5015, Train Acc: 0.7543, Val Loss: 0.5053, Val Acc: 0.7519\n","Epoch [9/20], Train Loss: 0.4936, Train Acc: 0.7541, Val Loss: 0.5173, Val Acc: 0.7367\n","Epoch [10/20], Train Loss: 0.4900, Train Acc: 0.7590, Val Loss: 0.4557, Val Acc: 0.7890\n","Epoch [11/20], Train Loss: 0.4591, Train Acc: 0.7839, Val Loss: 0.4152, Val Acc: 0.8089\n","Epoch [12/20], Train Loss: 0.4464, Train Acc: 0.7914, Val Loss: 0.4517, Val Acc: 0.7842\n","Epoch [13/20], Train Loss: 0.4369, Train Acc: 0.7987, Val Loss: 0.4488, Val Acc: 0.7842\n","Epoch [14/20], Train Loss: 0.4279, Train Acc: 0.8012, Val Loss: 0.5251, Val Acc: 0.7386\n","Epoch [15/20], Train Loss: 0.4198, Train Acc: 0.8034, Val Loss: 0.3874, Val Acc: 0.8222\n","Epoch [16/20], Train Loss: 0.4106, Train Acc: 0.8120, Val Loss: 0.4181, Val Acc: 0.7947\n","Epoch [17/20], Train Loss: 0.3985, Train Acc: 0.8216, Val Loss: 0.4071, Val Acc: 0.8137\n","Epoch [18/20], Train Loss: 0.4184, Train Acc: 0.8048, Val Loss: 0.3975, Val Acc: 0.8251\n","Epoch [19/20], Train Loss: 0.4008, Train Acc: 0.8128, Val Loss: 0.3622, Val Acc: 0.8413\n","Epoch [20/20], Train Loss: 0.3954, Train Acc: 0.8199, Val Loss: 0.3771, Val Acc: 0.8251\n","Saving model and scalers...\n","Training completed!\n"]}]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}