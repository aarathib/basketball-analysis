{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNmW3lXpI5aa1pj83LsM4WR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["\"\"\"feature_ablation_study.py\n","\n","This script extends the original train.py to perform feature group ablations:\n","1. Train with only ball trajectory features (no static features)\n","2. Train with only static features (no ball trajectory)\n","\"\"\"\n","\n","# Imports\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import MinMaxScaler\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import ast\n","import matplotlib.pyplot as plt\n","import os\n","import logging\n","import pickle\n","import time\n","from datetime import datetime\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Define paths - modify these to match your environment\n","data_path = '/content/drive/MyDrive/smai_project/dataset/dataset10/'\n","output_path = '/content/drive/MyDrive/smai_project/output_ablation_study/'\n","model_path = '/content/drive/MyDrive/smai_project/model_ablation_study/'\n","\n","# Create output and model directories if they don't exist\n","for path in [output_path, model_path]:\n","    if not os.path.exists(path):\n","        os.makedirs(path)\n","\n","# Set up logging\n","log_file_path = os.path.join(output_path, 'ablation_study.log')\n","logging.basicConfig(\n","    level=logging.INFO,\n","    format='%(asctime)s - %(message)s',\n","    handlers=[logging.FileHandler(log_file_path), logging.StreamHandler()]\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W7JcfwKdVw9H","executionInfo":{"status":"ok","timestamp":1746566519812,"user_tz":-330,"elapsed":1622,"user":{"displayName":"Aarathi Baburaj","userId":"17090552282489356926"}},"outputId":"ba3ee310-2f12-4c7f-d1ff-8b9412793247"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# Feature Extraction Function (same as original)\n","def extract_sequence_features(df):\n","    \"\"\"Extract features from ball and player sequences.\"\"\"\n","    def get_shooter_position(ball_seq, players_seq, personId):\n","        shooter_x, shooter_y = None, None\n","        if players_seq and isinstance(players_seq, list) and len(players_seq) > 0:\n","            first_frame = players_seq[0] if isinstance(players_seq[0], list) else players_seq\n","            if first_frame and isinstance(first_frame, list):\n","                for player in first_frame:\n","                    if len(player) != 5:\n","                        continue\n","                    _, player_id, x, y, _ = player\n","                    if player_id == personId:\n","                        shooter_x, shooter_y = x, y\n","                        break\n","\n","        if shooter_x is None or shooter_y is None:\n","            if not ball_seq or not isinstance(ball_seq, list) or len(ball_seq) == 0:\n","                return 0, 0\n","            first_pos = ball_seq[0]\n","            if not isinstance(first_pos, list) or len(first_pos) != 3:\n","                return 0, 0\n","            shooter_x, shooter_y, _ = first_pos\n","        return shooter_x, shooter_y\n","\n","    df['shooter_x'], df['shooter_y'] = zip(*df.apply(\n","        lambda row: get_shooter_position(row['ball_seq'], row['players_seq'], row['personId']), axis=1\n","    ))\n","\n","    df['initial_height'] = df['ball_seq'].apply(lambda seq: seq[0][2] if len(seq) > 0 and len(seq[0]) == 3 else 0)\n","    df['max_height'] = df['ball_seq'].apply(lambda seq: max([point[2] for point in seq]) if len(seq) > 0 and all(len(point) == 3 for point in seq) else 0)\n","    df['traj_length'] = df['ball_seq'].apply(len)\n","    df['shotDistance'] = df.apply(\n","        lambda row: np.sqrt((row['shooter_x'] - row['basket_x'])**2 + (row['shooter_y'] - row['basket_y'])**2), axis=1\n","    )\n","    df['shotDistance'] = df['shotDistance'].replace(0, 1)\n","    df['traj_curvature'] = df['max_height'] / df['shotDistance']\n","\n","    df['release_angle'] = df.apply(\n","        lambda row: np.arctan2(row['shooter_y'] - row['basket_y'], row['shooter_x'] - row['basket_x']), axis=1\n","    )\n","\n","    def calculate_defender_proximity(shooter_x, shooter_y, players_seq):\n","        min_distance = float('inf')\n","        shooter_team_id = None\n","\n","        if not players_seq or not isinstance(players_seq, list) or len(players_seq) == 0:\n","            return 0\n","\n","        first_frame = players_seq[0] if isinstance(players_seq[0], list) else players_seq\n","        if not first_frame or not isinstance(first_frame, list):\n","            return 0\n","\n","        closest_player_distance = float('inf')\n","        for player in first_frame:\n","            if len(player) != 5:\n","                continue\n","            team_id, _, x, y, _ = player\n","            distance = np.sqrt((shooter_x - x)**2 + (shooter_y - y)**2)\n","            if distance < closest_player_distance:\n","                closest_player_distance = distance\n","                shooter_team_id = team_id\n","\n","        if shooter_team_id is None:\n","            logging.warning(f\"Could not determine shooter team for position ({shooter_x}, {shooter_y})\")\n","            return 0\n","\n","        for player in first_frame:\n","            if len(player) != 5:\n","                continue\n","            team_id, _, x, y, _ = player\n","            if team_id == shooter_team_id:\n","                continue\n","            distance = np.sqrt((shooter_x - x)**2 + (shooter_y - y)**2)\n","            min_distance = min(min_distance, distance)\n","        return min_distance if min_distance != float('inf') else 0\n","\n","    df['defender_proximity'] = df.apply(\n","        lambda row: calculate_defender_proximity(row['shooter_x'], row['shooter_y'], row['players_seq']), axis=1\n","    )\n","\n","    def extract_player_positions(players_seq, shooter_x, shooter_y):\n","        shooter_team_id = None\n","        teammates = []\n","        defenders = []\n","\n","        if not players_seq or not isinstance(players_seq, list) or len(players_seq) == 0:\n","            return [0, 0, 0, 0]\n","\n","        first_frame = players_seq[0] if isinstance(players_seq[0], list) else players_seq\n","        if not first_frame or not isinstance(first_frame, list):\n","            return [0, 0, 0, 0]\n","\n","        closest_player_distance = float('inf')\n","        for player in first_frame:\n","            if len(player) != 5:\n","                continue\n","            team_id, _, x, y, _ = player\n","            distance = np.sqrt((shooter_x - x)**2 + (shooter_y - y)**2)\n","            if distance < closest_player_distance:\n","                closest_player_distance = distance\n","                shooter_team_id = team_id\n","\n","        if shooter_team_id is None:\n","            logging.warning(f\"Could not determine shooter team for position ({shooter_x}, {shooter_y})\")\n","            return [0, 0, 0, 0]\n","\n","        for player in first_frame:\n","            if len(player) != 5:\n","                continue\n","            team_id, _, x, y, _ = player\n","            if team_id == shooter_team_id:\n","                teammates.append([x, y])\n","            else:\n","                defenders.append([x, y])\n","\n","        closest_teammate = [0, 0]\n","        if teammates:\n","            teammate_distances = [(np.sqrt((shooter_x - tx)**2 + (shooter_y - ty)**2), tx, ty) for tx, ty in teammates]\n","            teammate_distances.sort()\n","            closest_teammate = [teammate_distances[1][1], teammate_distances[1][2]] if len(teammate_distances) > 1 else teammate_distances[0][1:3]\n","\n","        closest_defender = [0, 0]\n","        if defenders:\n","            defender_distances = [(np.sqrt((shooter_x - dx)**2 + (shooter_y - dy)**2), dx, dy) for dx, dy in defenders]\n","            defender_distances.sort()\n","            closest_defender = [defender_distances[0][1], defender_distances[0][2]]\n","\n","        return closest_teammate + closest_defender\n","\n","    df[['teammate_x', 'teammate_y', 'defender_x', 'defender_y']] = df.apply(\n","        lambda row: extract_player_positions(row['players_seq'], row['shooter_x'], row['shooter_y']), axis=1, result_type='expand'\n","    )\n","\n","    def extract_ball_dynamics(ball_seq):\n","        if not ball_seq or len(ball_seq) < 3:\n","            return [0, 0, 0, 0, 0, 0]\n","\n","        velocities = []\n","        for i in range(1, len(ball_seq)):\n","            if len(ball_seq[i]) != 3 or len(ball_seq[i-1]) != 3:\n","                continue\n","            dx = ball_seq[i][0] - ball_seq[i-1][0]\n","            dy = ball_seq[i][1] - ball_seq[i-1][1]\n","            dz = ball_seq[i][2] - ball_seq[i-1][2]\n","            velocities.append([dx, dy, dz])\n","\n","        if not velocities:\n","            return [0, 0, 0, 0, 0, 0]\n","\n","        accelerations = []\n","        for i in range(1, len(velocities)):\n","            ax = velocities[i][0] - velocities[i-1][0]\n","            ay = velocities[i][1] - velocities[i-1][1]\n","            az = velocities[i][2] - velocities[i-1][2]\n","            accelerations.append([ax, ay, az])\n","\n","        if not accelerations:\n","            avg_vel_x = np.mean([v[0] for v in velocities])\n","            avg_vel_y = np.mean([v[1] for v in velocities])\n","            avg_vel_z = np.mean([v[2] for v in velocities])\n","            return [avg_vel_x, avg_vel_y, avg_vel_z, 0, 0, 0]\n","\n","        avg_vel_x = np.mean([v[0] for v in velocities])\n","        avg_vel_y = np.mean([v[1] for v in velocities])\n","        avg_vel_z = np.mean([v[2] for v in velocities])\n","        avg_acc_x = np.mean([a[0] for a in accelerations])\n","        avg_acc_y = np.mean([a[1] for a in accelerations])\n","        avg_acc_z = np.mean([a[2] for a in accelerations])\n","\n","        return [avg_vel_x, avg_vel_y, avg_vel_z, avg_acc_x, avg_acc_y, avg_acc_z]\n","\n","    df[['avg_vel_x', 'avg_vel_y', 'avg_vel_z', 'avg_acc_x', 'avg_acc_y', 'avg_acc_z']] = df['ball_seq'].apply(\n","        lambda seq: extract_ball_dynamics(seq)\n","    ).apply(pd.Series)\n","\n","    def extract_shot_arc(ball_seq, basket_x, basket_y):\n","        if not ball_seq or len(ball_seq) < 3:\n","            return [0, 0]\n","\n","        try:\n","            release_x, release_y, release_z = ball_seq[0]\n","            peak_idx = max(range(len(ball_seq)), key=lambda i: ball_seq[i][2] if len(ball_seq[i]) == 3 else 0)\n","            peak_x, peak_y, peak_z = ball_seq[peak_idx]\n","\n","            last_valid_idx = -1\n","            for i in range(len(ball_seq)-1, 0, -1):\n","                if len(ball_seq[i]) == 3:\n","                    last_valid_idx = i\n","                    break\n","\n","            if last_valid_idx <= 0:\n","                return [0, 0]\n","\n","            p2 = ball_seq[last_valid_idx]\n","            p1 = ball_seq[max(0, last_valid_idx-1)]\n","\n","            if len(p1) != 3 or len(p2) != 3:\n","                return [0, 0]\n","\n","            horizontal_dist = np.sqrt((p2[0] - p1[0])**2 + (p2[1] - p1[1])**2)\n","            entry_angle = 90 if horizontal_dist == 0 else np.degrees(np.arctan2(p2[2] - p1[2], horizontal_dist))\n","\n","            total_dist = np.sqrt((basket_x - release_x)**2 + (basket_y - release_y)**2)\n","            arc_height_ratio = 0 if total_dist == 0 else peak_z / total_dist\n","\n","            return [entry_angle, arc_height_ratio]\n","        except Exception as e:\n","            logging.error(f\"Error extracting shot arc: {e}\")\n","            return [0, 0]\n","\n","    df[['entry_angle', 'arc_height_ratio']] = df.apply(\n","        lambda row: extract_shot_arc(row['ball_seq'], row['basket_x'], row['basket_y']),\n","        axis=1, result_type='expand'\n","    )\n","\n","    return df\n","\n","# Sequence Processing Function (same as original)\n","def process_ball_sequences(df):\n","    \"\"\"Process ball sequences for LSTM input.\"\"\"\n","    sequences = []\n","    labels = []\n","\n","    for _, row in df.iterrows():\n","        ball_seq = row['ball_seq']\n","        result = row['shotResult']\n","\n","        if len(ball_seq) > 37:\n","            ball_seq = ball_seq[:37]\n","        elif len(ball_seq) < 37:\n","            last_pos = ball_seq[-1] if ball_seq else [0, 0, 0]\n","            while len(ball_seq) < 37:\n","                ball_seq.append(last_pos)\n","\n","        sequence = []\n","        for moment in ball_seq:\n","            if isinstance(moment, list) and len(moment) == 3:\n","                sequence.append(moment)\n","            else:\n","                sequence.append([0, 0, 0])\n","\n","        sequences.append(sequence)\n","        labels.append(result)\n","\n","    return np.array(sequences), np.array(labels)\n","\n","# PyTorch Dataset modified to handle ablation studies\n","class ShotDataset(Dataset):\n","    \"\"\"Custom Dataset for basketball shot data with options for feature ablation.\"\"\"\n","    def __init__(self, ball_sequences=None, static_features=None, labels=None):\n","        # For only-ball scenario, static_features might be None\n","        # For only-static scenario, ball_sequences might be None\n","        self.ball_sequences = None if ball_sequences is None else torch.tensor(ball_sequences, dtype=torch.float32)\n","        self.static_features = None if static_features is None else torch.tensor(static_features, dtype=torch.float32)\n","        self.labels = torch.tensor(labels, dtype=torch.float32)\n","\n","        # Placeholder for only-static scenario\n","        if ball_sequences is None:\n","            self.use_ball = False\n","        else:\n","            self.use_ball = True\n","\n","        # Placeholder for only-ball scenario\n","        if static_features is None:\n","            self.use_static = False\n","        else:\n","            self.use_static = True\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        if self.use_ball and self.use_static:\n","            return self.ball_sequences[idx], self.static_features[idx], self.labels[idx]\n","        elif self.use_ball:\n","            return self.ball_sequences[idx], self.labels[idx]\n","        else:  # use_static only\n","            return self.static_features[idx], self.labels[idx]"],"metadata":{"id":"roiwT7MwWMR2","executionInfo":{"status":"ok","timestamp":1746566519856,"user_tz":-330,"elapsed":7,"user":{"displayName":"Aarathi Baburaj","userId":"17090552282489356926"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# Define PyTorch Models for different ablation scenarios\n","class BallOnlyPredictor(nn.Module):\n","    \"\"\"Model using only ball trajectory features.\"\"\"\n","    def __init__(self, ball_input_size=3, hidden_size=64):\n","        super(BallOnlyPredictor, self).__init__()\n","        self.lstm1 = nn.LSTM(ball_input_size, hidden_size, batch_first=True)\n","        self.dropout1 = nn.Dropout(0.2)\n","        self.lstm2 = nn.LSTM(hidden_size, hidden_size // 2, batch_first=True)\n","        self.dropout2 = nn.Dropout(0.2)\n","\n","        self.fc = nn.Linear(hidden_size // 2, 32)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(0.2)\n","        self.fc_out = nn.Linear(32, 1)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, ball_seq):\n","        # Ball sequence processing\n","        lstm_out, _ = self.lstm1(ball_seq)\n","        lstm_out = self.dropout1(lstm_out)\n","        lstm_out, _ = self.lstm2(lstm_out)\n","        lstm_out = self.dropout2(lstm_out)\n","        lstm_out = lstm_out[:, -1, :]  # Take the last time step\n","\n","        # Final layers\n","        out = self.fc(lstm_out)\n","        out = self.relu(out)\n","        out = self.dropout(out)\n","        out = self.fc_out(out)\n","        out = self.sigmoid(out)\n","        return out\n","\n","class StaticOnlyPredictor(nn.Module):\n","    \"\"\"Model using only static features.\"\"\"\n","    def __init__(self, static_input_size=20):\n","        super(StaticOnlyPredictor, self).__init__()\n","        self.fc1 = nn.Linear(static_input_size, 64)\n","        self.relu1 = nn.ReLU()\n","        self.dropout1 = nn.Dropout(0.2)\n","\n","        self.fc2 = nn.Linear(64, 32)\n","        self.relu2 = nn.ReLU()\n","        self.dropout2 = nn.Dropout(0.2)\n","\n","        self.fc_out = nn.Linear(32, 1)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, static_features):\n","        # Static features processing\n","        out = self.fc1(static_features)\n","        out = self.relu1(out)\n","        out = self.dropout1(out)\n","\n","        out = self.fc2(out)\n","        out = self.relu2(out)\n","        out = self.dropout2(out)\n","\n","        out = self.fc_out(out)\n","        out = self.sigmoid(out)\n","        return out\n","\n","class CombinedPredictor(nn.Module):\n","    \"\"\"Original combined model as baseline.\"\"\"\n","    def __init__(self, ball_input_size=3, static_input_size=20, hidden_size=64):\n","        super(CombinedPredictor, self).__init__()\n","        self.lstm1 = nn.LSTM(ball_input_size, hidden_size, batch_first=True)\n","        self.dropout1 = nn.Dropout(0.2)\n","        self.lstm2 = nn.LSTM(hidden_size, hidden_size // 2, batch_first=True)\n","        self.dropout2 = nn.Dropout(0.2)\n","\n","        self.static_fc1 = nn.Linear(static_input_size, 32)\n","        self.static_relu = nn.ReLU()\n","        self.static_dropout = nn.Dropout(0.2)\n","\n","        self.fc_combined = nn.Linear(hidden_size // 2 + 32, 32)\n","        self.relu_combined = nn.ReLU()\n","        self.dropout_combined = nn.Dropout(0.2)\n","        self.fc_out = nn.Linear(32, 1)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, ball_seq, static_features):\n","        # Ball sequence processing\n","        lstm_out, _ = self.lstm1(ball_seq)\n","        lstm_out = self.dropout1(lstm_out)\n","        lstm_out, _ = self.lstm2(lstm_out)\n","        lstm_out = self.dropout2(lstm_out)\n","        lstm_out = lstm_out[:, -1, :]  # Take the last time step\n","\n","        # Static features processing\n","        static_out = self.static_fc1(static_features)\n","        static_out = self.static_relu(static_out)\n","        static_out = self.static_dropout(static_out)\n","\n","        # Combine\n","        combined = torch.cat((lstm_out, static_out), dim=1)\n","        out = self.fc_combined(combined)\n","        out = self.relu_combined(out)\n","        out = self.dropout_combined(out)\n","        out = self.fc_out(out)\n","        out = self.sigmoid(out)\n","        return out"],"metadata":{"id":"kZnc4xk6WwIK","executionInfo":{"status":"ok","timestamp":1746566519858,"user_tz":-330,"elapsed":1,"user":{"displayName":"Aarathi Baburaj","userId":"17090552282489356926"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# Training function\n","def train_model(model_type, train_loader, val_loader, device, static_features, num_epochs=20):\n","    \"\"\"Train and evaluate model based on specified type.\"\"\"\n","\n","    if model_type == \"ball_only\":\n","        model = BallOnlyPredictor().to(device)\n","    elif model_type == \"static_only\":\n","        model = StaticOnlyPredictor(static_input_size=len(static_features)).to(device)\n","    else:  # combined\n","        model = CombinedPredictor(ball_input_size=3, static_input_size=len(static_features)).to(device)\n","\n","    criterion = nn.BCELoss()\n","    optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","    train_losses = []\n","    val_losses = []\n","    train_accuracies = []\n","    val_accuracies = []\n","\n","    for epoch in range(num_epochs):\n","        # Training\n","        model.train()\n","        running_loss = 0.0\n","        correct = 0\n","        total = 0\n","\n","        for batch in train_loader:\n","            if model_type == \"combined\":\n","                ball_seq, static_features, labels = batch\n","                ball_seq, static_features, labels = ball_seq.to(device), static_features.to(device), labels.to(device)\n","\n","                optimizer.zero_grad()\n","                outputs = model(ball_seq, static_features).squeeze()\n","\n","            elif model_type == \"ball_only\":\n","                ball_seq, labels = batch\n","                ball_seq, labels = ball_seq.to(device), labels.to(device)\n","\n","                optimizer.zero_grad()\n","                outputs = model(ball_seq).squeeze()\n","\n","            else:  # static_only\n","                static_features, labels = batch\n","                static_features, labels = static_features.to(device), labels.to(device)\n","\n","                optimizer.zero_grad()\n","                outputs = model(static_features).squeeze()\n","\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item() * labels.size(0)\n","            predicted = (outputs > 0.5).float()\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","        epoch_loss = running_loss / total\n","        epoch_acc = correct / total\n","        train_losses.append(epoch_loss)\n","        train_accuracies.append(epoch_acc)\n","\n","        # Validation\n","        model.eval()\n","        val_loss = 0.0\n","        correct = 0\n","        total = 0\n","\n","        with torch.no_grad():\n","            for batch in val_loader:\n","                if model_type == \"combined\":\n","                    ball_seq, static_features, labels = batch\n","                    ball_seq, static_features, labels = ball_seq.to(device), static_features.to(device), labels.to(device)\n","                    outputs = model(ball_seq, static_features).squeeze()\n","\n","                elif model_type == \"ball_only\":\n","                    ball_seq, labels = batch\n","                    ball_seq, labels = ball_seq.to(device), labels.to(device)\n","                    outputs = model(ball_seq).squeeze()\n","\n","                else:  # static_only\n","                    static_features, labels = batch\n","                    static_features, labels = static_features.to(device), labels.to(device)\n","                    outputs = model(static_features).squeeze()\n","\n","                loss = criterion(outputs, labels)\n","                val_loss += loss.item() * labels.size(0)\n","                predicted = (outputs > 0.5).float()\n","                total += labels.size(0)\n","                correct += (predicted == labels).sum().item()\n","\n","        val_loss = val_loss / total\n","        val_acc = correct / total\n","        val_losses.append(val_loss)\n","        val_accuracies.append(val_acc)\n","\n","        logging.info(f'[{model_type}] Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n","\n","    # Save model and metrics\n","    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","    model_filename = f\"{model_type}_model_{timestamp}.pth\"\n","    torch.save(model.state_dict(), os.path.join(model_path, model_filename))\n","\n","    # Plot and save training metrics\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(train_accuracies, label='Training Accuracy')\n","    plt.plot(val_accuracies, label='Validation Accuracy')\n","    plt.title(f'{model_type.replace(\"_\", \" \").title()} Model: Accuracy Over Epochs')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Accuracy')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.savefig(os.path.join(output_path, f'{model_type}_accuracy_over_epochs.png'))\n","    plt.close()\n","\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(train_losses, label='Training Loss')\n","    plt.plot(val_losses, label='Validation Loss')\n","    plt.title(f'{model_type.replace(\"_\", \" \").title()} Model: Loss Over Epochs')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.savefig(os.path.join(output_path, f'{model_type}_loss_over_epochs.png'))\n","    plt.close()\n","\n","    return model, train_accuracies[-1], val_accuracies[-1]"],"metadata":{"id":"VypStLHgW5mF","executionInfo":{"status":"ok","timestamp":1746566519872,"user_tz":-330,"elapsed":4,"user":{"displayName":"Aarathi Baburaj","userId":"17090552282489356926"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import precision_score, recall_score, f1_score\n","import logging\n","import torch\n","\n","def evaluate_model(model, model_type, test_loader, device, static_features):\n","    \"\"\"Evaluate model on test set with accuracy, precision, recall, and F1 score.\"\"\"\n","    model.eval()\n","    correct = 0\n","    total = 0\n","\n","    all_labels = []\n","    all_preds = []\n","\n","    with torch.no_grad():\n","        for batch in test_loader:\n","            if model_type == \"combined\":\n","                ball_seq, static_features, labels = batch\n","                ball_seq, static_features, labels = ball_seq.to(device), static_features.to(device), labels.to(device)\n","                outputs = model(ball_seq, static_features).squeeze()\n","\n","            elif model_type == \"ball_only\":\n","                ball_seq, labels = batch\n","                ball_seq, labels = ball_seq.to(device), labels.to(device)\n","                outputs = model(ball_seq).squeeze()\n","\n","            else:  # static_only\n","                static_features, labels = batch\n","                static_features, labels = static_features.to(device), labels.to(device)\n","                outputs = model(static_features).squeeze()\n","\n","            predicted = (outputs > 0.5).float()\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","            all_labels.extend(labels.cpu().numpy())\n","            all_preds.extend(predicted.cpu().numpy())\n","\n","    test_acc = correct / total\n","    precision = precision_score(all_labels, all_preds, zero_division=0)\n","    recall = recall_score(all_labels, all_preds, zero_division=0)\n","    f1 = f1_score(all_labels, all_preds, zero_division=0)\n","\n","    logging.info(f'[{model_type}] Test Accuracy: {test_acc:.4f}')\n","    logging.info(f'[{model_type}] Precision: {precision:.4f}')\n","    logging.info(f'[{model_type}] Recall: {recall:.4f}')\n","    logging.info(f'[{model_type}] F1 Score: {f1:.4f}')\n","\n","    return test_acc, precision, recall, f1\n"],"metadata":{"id":"I_yu8_fPXH4K","executionInfo":{"status":"ok","timestamp":1746566519881,"user_tz":-330,"elapsed":8,"user":{"displayName":"Aarathi Baburaj","userId":"17090552282489356926"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","execution_count":26,"metadata":{"id":"i0GUIervVW1y","executionInfo":{"status":"ok","timestamp":1746566519921,"user_tz":-330,"elapsed":39,"user":{"displayName":"Aarathi Baburaj","userId":"17090552282489356926"}}},"outputs":[],"source":["# # Main function to run the ablation study\n","# def run_ablation_study():\n","#     \"\"\"Run the complete ablation study.\"\"\"\n","#     # Load and preprocess data\n","#     print(\"Loading datasets...\")\n","#     train_df = pd.read_csv(data_path + 'train.csv')\n","#     val_df = pd.read_csv(data_path + 'val.csv')\n","#     test_df = pd.read_csv(data_path + 'test.csv')\n","\n","#     # Parse sequences\n","#     for df in [train_df, val_df, test_df]:\n","#         df['players_seq'] = df['players_seq'].apply(ast.literal_eval)\n","#         df['ball_seq'] = df['ball_seq'].apply(ast.literal_eval)\n","\n","#     # Filter shots and encode labels\n","#     for df in [train_df, val_df, test_df]:\n","#         df.drop(df[~df['shotResult'].isin(['Made Shot', 'Missed Shot'])].index, inplace=True)\n","#         df['shotResult'] = df['shotResult'].map({'Made Shot': 1, 'Missed Shot': 0})\n","\n","#     # Extract features\n","#     print(\"Extracting features...\")\n","#     train_df = extract_sequence_features(train_df)\n","#     val_df = extract_sequence_features(val_df)\n","#     test_df = extract_sequence_features(test_df)\n","\n","#     static_features = [\n","#         'shooter_x', 'shooter_y', 'release_angle', 'initial_height', 'max_height',\n","#         'traj_length', 'traj_curvature', 'defender_proximity',\n","#         'teammate_x', 'teammate_y', 'defender_x', 'defender_y',\n","#         'avg_vel_x', 'avg_vel_y', 'avg_vel_z', 'avg_acc_x', 'avg_acc_y', 'avg_acc_z',\n","#         'entry_angle', 'arc_height_ratio'\n","#     ]\n","\n","#     # Clean up NaN or inf values\n","#     for df in [train_df, val_df, test_df]:\n","#         df[static_features] = df[static_features].replace([np.inf, -np.inf], 0).fillna(0)\n","\n","#     # Process ball sequences\n","#     print(\"Processing ball sequences...\")\n","#     X_train_ball, y_train = process_ball_sequences(train_df)\n","#     X_val_ball, y_val = process_ball_sequences(val_df)\n","#     X_test_ball, y_test = process_ball_sequences(test_df)\n","\n","#     # Reshape for LSTM\n","#     X_train_ball = X_train_ball.reshape(X_train_ball.shape[0], 37, 3)\n","#     X_val_ball = X_val_ball.reshape(X_val_ball.shape[0], 37, 3)\n","#     X_test_ball = X_test_ball.reshape(X_test_ball.shape[0], 37, 3)\n","\n","#     # Normalize ball sequences\n","#     scaler_ball = MinMaxScaler()\n","#     X_train_ball_2d = X_train_ball.reshape(-1, 3)\n","#     X_train_ball_2d = scaler_ball.fit_transform(X_train_ball_2d)\n","#     X_train_ball = X_train_ball_2d.reshape(X_train_ball.shape)\n","\n","#     X_val_ball_2d = X_val_ball.reshape(-1, 3)\n","#     X_val_ball_2d = scaler_ball.transform(X_val_ball_2d)\n","#     X_val_ball = X_val_ball_2d.reshape(X_val_ball.shape)\n","\n","#     X_test_ball_2d = X_test_ball.reshape(-1, 3)\n","#     X_test_ball_2d = scaler_ball.transform(X_test_ball_2d)\n","#     X_test_ball = X_test_ball_2d.reshape(X_test_ball.shape)\n","\n","#     # Process static features\n","#     X_train_static = train_df[static_features].values\n","#     X_val_static = val_df[static_features].values\n","#     X_test_static = test_df[static_features].values\n","\n","#     # Normalize static features\n","#     scaler_static = MinMaxScaler()\n","#     X_train_static = scaler_static.fit_transform(X_train_static)\n","#     X_val_static = scaler_static.transform(X_val_static)\n","#     X_test_static = scaler_static.transform(X_test_static)\n","\n","#     # Save scalers for future use\n","#     with open(os.path.join(model_path, 'scaler_ball.pkl'), 'wb') as f:\n","#         pickle.dump(scaler_ball, f)\n","#     with open(os.path.join(model_path, 'scaler_static.pkl'), 'wb') as f:\n","#         pickle.dump(scaler_static, f)\n","\n","#     # Create datasets for each ablation scenario\n","#     batch_size = 32\n","#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","#     # 1. Combined model (baseline)\n","#     print(\"\\n=== Training Combined Model (Baseline) ===\")\n","#     combined_train_dataset = ShotDataset(X_train_ball, X_train_static, y_train)\n","#     combined_val_dataset = ShotDataset(X_val_ball, X_val_static, y_val)\n","#     combined_test_dataset = ShotDataset(X_test_ball, X_test_static, y_test)\n","\n","#     combined_train_loader = DataLoader(combined_train_dataset, batch_size=batch_size, shuffle=True)\n","#     combined_val_loader = DataLoader(combined_val_dataset, batch_size=batch_size, shuffle=False)\n","#     combined_test_loader = DataLoader(combined_test_dataset, batch_size=batch_size, shuffle=False)\n","\n","#     combined_model, combined_train_acc, combined_val_acc = train_model(\n","#         \"combined\", combined_train_loader, combined_val_loader, device, static_features\n","#     )\n","#     combined_test_acc = evaluate_model(combined_model, \"combined\", combined_test_loader, device, static_features)\n","\n","#     # 2. Ball-only model\n","#     print(\"\\n=== Training Ball-Only Model ===\")\n","#     ball_train_dataset = ShotDataset(ball_sequences=X_train_ball, static_features=None, labels=y_train)\n","#     ball_val_dataset = ShotDataset(ball_sequences=X_val_ball, static_features=None, labels=y_val)\n","#     ball_test_dataset = ShotDataset(ball_sequences=X_test_ball, static_features=None, labels=y_test)\n","\n","#     ball_train_loader = DataLoader(ball_train_dataset, batch_size=batch_size, shuffle=True)\n","#     ball_val_loader = DataLoader(ball_val_dataset, batch_size=batch_size, shuffle=False)\n","#     ball_test_loader = DataLoader(ball_test_dataset, batch_size=batch_size, shuffle=False)\n","\n","#     ball_model, ball_train_acc, ball_val_acc = train_model(\n","#         \"ball_only\", ball_train_loader, ball_val_loader, device, static_features\n","#     )\n","#     ball_test_acc = evaluate_model(ball_model, \"ball_only\", ball_test_loader, device, static_features)\n","\n","#     # 3. Static-only model\n","#     print(\"\\n=== Training Static-Only Model ===\")\n","#     static_train_dataset = ShotDataset(ball_sequences=None, static_features=X_train_static, labels=y_train)\n","#     static_val_dataset = ShotDataset(ball_sequences=None, static_features=X_val_static, labels=y_val)\n","#     static_test_dataset = ShotDataset(ball_sequences=None, static_features=X_test_static, labels=y_test)\n","\n","#     static_train_loader = DataLoader(static_train_dataset, batch_size=batch_size, shuffle=True)\n","#     static_val_loader = DataLoader(static_val_dataset, batch_size=batch_size, shuffle=False)\n","#     static_test_loader = DataLoader(static_test_dataset, batch_size=batch_size, shuffle=False)\n","\n","#     static_model, static_train_acc, static_val_acc = train_model(\n","#         \"static_only\", static_train_loader, static_val_loader, device, static_features\n","#     )\n","#     static_test_acc = evaluate_model(static_model, \"static_only\", static_test_loader, device, static_features)\n","\n","#     # Summary of results\n","#     results = {\n","#         \"Combined Model\": {\n","#             \"Train Accuracy\": combined_train_acc,\n","#             \"Validation Accuracy\": combined_val_acc,\n","#             \"Test Accuracy\": combined_test_acc\n","#         },\n","#         \"Ball-Only Model\": {\n","#             \"Train Accuracy\": ball_train_acc,\n","#             \"Validation Accuracy\": ball_val_acc,\n","#             \"Test Accuracy\": ball_test_acc\n","#         },\n","#         \"Static-Only Model\": {\n","#             \"Train Accuracy\": static_train_acc,\n","#             \"Validation Accuracy\": static_val_acc,\n","#             \"Test Accuracy\": static_test_acc\n","#         }\n","#     }\n","\n","#     # Print summary table\n","#     print(\"\\n===== ABLATION STUDY RESULTS =====\")\n","#     print(f\"{'Model':<20} {'Train Acc':<15} {'Val Acc':<15} {'Test Acc':<15}\")\n","#     print(\"-\" * 65)\n","#     for model_name, metrics in results.items():\n","#         print(f\"{model_name:<20} {metrics['Train Accuracy']:<15.4f} {metrics['Validation Accuracy']:<15.4f} {metrics['Test Accuracy']:<15.4f}\")\n","\n","#     # Save results to file\n","#     with open(os.path.join(output_path, 'ablation_results.txt'), 'w') as f:\n","#         f.write(\"===== ABLATION STUDY RESULTS =====\\n\")\n","#         f.write(f\"{'Model':<20} {'Train Acc':<15} {'Val Acc':<15} {'Test Acc':<15}\\n\")\n","#         f.write(\"-\" * 65 + \"\\n\")\n","#         for model_name, metrics in results.items():\n","#             f.write(f\"{model_name:<20} {metrics['Train Accuracy']:<15.4f} {metrics['Validation Accuracy']:<15.4f} {metrics['Test Accuracy']:<15.4f}\\n\")\n","\n","#     # Create comparison bar plot\n","#     plt.figure(figsize=(12, 8))\n","#     models = list(results.keys())\n","#     train_accs = [results[m][\"Train Accuracy\"] for m in models]\n","#     val_accs = [results[m][\"Validation Accuracy\"] for m in models]\n","#     test_accs = [results[m][\"Test Accuracy\"] for m in models]\n","\n","#     x = np.arange(len(models))\n","#     width = 0.25\n","\n","#     plt.bar(x - width, train_accs, width, label='Train Accuracy')\n","#     plt.bar(x, val_accs, width, label='Validation Accuracy')\n","#     plt.bar(x + width, test_accs, width, label='Test Accuracy')\n","\n","#     plt.xlabel('Models')\n","#     plt.ylabel('Accuracy')\n","#     plt.title('Comparison of Model Performance Across Ablation Studies')\n","#     plt.xticks(x, models)\n","#     plt.legend()\n","#     plt.grid(axis='y', alpha=0.3)\n","\n","#     plt.tight_layout()\n","#     plt.savefig(os.path.join(output_path, 'ablation_comparison.png'))\n","#     plt.close()\n","\n","#     print(f\"Results saved to {output_path}\")\n","#     return results"]},{"cell_type":"code","source":["# Main function to run the ablation study\n","def run_ablation_study():\n","    \"\"\"Run the complete ablation study.\"\"\"\n","    # Load and preprocess data\n","    print(\"Loading datasets...\")\n","    train_df = pd.read_csv(data_path + 'train.csv')\n","    val_df = pd.read_csv(data_path + 'val.csv')\n","    test_df = pd.read_csv(data_path + 'test.csv')\n","\n","    # Parse sequences\n","    for df in [train_df, val_df, test_df]:\n","        df['players_seq'] = df['players_seq'].apply(ast.literal_eval)\n","        df['ball_seq'] = df['ball_seq'].apply(ast.literal_eval)\n","\n","    # Filter shots and encode labels\n","    for df in [train_df, val_df, test_df]:\n","        df.drop(df[~df['shotResult'].isin(['Made Shot', 'Missed Shot'])].index, inplace=True)\n","        df['shotResult'] = df['shotResult'].map({'Made Shot': 1, 'Missed Shot': 0})\n","\n","    # Extract features\n","    print(\"Extracting features...\")\n","    train_df = extract_sequence_features(train_df)\n","    val_df = extract_sequence_features(val_df)\n","    test_df = extract_sequence_features(test_df)\n","\n","    # Define static features\n","    static_features = [\n","        'shooter_x', 'shooter_y', 'release_angle', 'initial_height', 'max_height',\n","        'traj_length', 'traj_curvature', 'defender_proximity',\n","        'teammate_x', 'teammate_y', 'defender_x', 'defender_y',\n","        'avg_vel_x', 'avg_vel_y', 'avg_vel_z', 'avg_acc_x', 'avg_acc_y', 'avg_acc_z',\n","        'entry_angle', 'arc_height_ratio'\n","    ]\n","\n","    # Clean up NaN or inf values\n","    for df in [train_df, val_df, test_df]:\n","        df[static_features] = df[static_features].replace([np.inf, -np.inf], 0).fillna(0)\n","\n","    # Process ball sequences\n","    print(\"Processing ball sequences...\")\n","    X_train_ball, y_train = process_ball_sequences(train_df)\n","    X_val_ball, y_val = process_ball_sequences(val_df)\n","    X_test_ball, y_test = process_ball_sequences(test_df)\n","\n","    # Reshape for LSTM\n","    X_train_ball = X_train_ball.reshape(X_train_ball.shape[0], 37, 3)\n","    X_val_ball = X_val_ball.reshape(X_val_ball.shape[0], 37, 3)\n","    X_test_ball = X_test_ball.reshape(X_test_ball.shape[0], 37, 3)\n","\n","    # Normalize ball sequences\n","    scaler_ball = MinMaxScaler()\n","    X_train_ball_2d = X_train_ball.reshape(-1, 3)\n","    X_train_ball_2d = scaler_ball.fit_transform(X_train_ball_2d)\n","    X_train_ball = X_train_ball_2d.reshape(X_train_ball.shape)\n","\n","    X_val_ball_2d = X_val_ball.reshape(-1, 3)\n","    X_val_ball_2d = scaler_ball.transform(X_val_ball_2d)\n","    X_val_ball = X_val_ball_2d.reshape(X_val_ball.shape)\n","\n","    X_test_ball_2d = X_test_ball.reshape(-1, 3)\n","    X_test_ball_2d = scaler_ball.transform(X_test_ball_2d)\n","    X_test_ball = X_test_ball_2d.reshape(X_test_ball.shape)\n","\n","    # Process static features\n","    X_train_static = train_df[static_features].values\n","    X_val_static = val_df[static_features].values\n","    X_test_static = test_df[static_features].values\n","\n","    # Normalize static features\n","    scaler_static = MinMaxScaler()\n","    X_train_static = scaler_static.fit_transform(X_train_static)\n","    X_val_static = scaler_static.transform(X_val_static)\n","    X_test_static = scaler_static.transform(X_test_static)\n","\n","    # Save scalers for future use\n","    with open(os.path.join(model_path, 'scaler_ball.pkl'), 'wb') as f:\n","        pickle.dump(scaler_ball, f)\n","    with open(os.path.join(model_path, 'scaler_static.pkl'), 'wb') as f:\n","        pickle.dump(scaler_static, f)\n","\n","    # Create datasets for each ablation scenario\n","    batch_size = 32\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    # 1. Combined model (baseline)\n","    print(\"\\n=== Training Combined Model (Baseline) ===\")\n","    combined_train_dataset = ShotDataset(X_train_ball, X_train_static, y_train)\n","    combined_val_dataset = ShotDataset(X_val_ball, X_val_static, y_val)\n","    combined_test_dataset = ShotDataset(X_test_ball, X_test_static, y_test)\n","\n","    combined_train_loader = DataLoader(combined_train_dataset, batch_size=batch_size, shuffle=True)\n","    combined_val_loader = DataLoader(combined_val_dataset, batch_size=batch_size, shuffle=False)\n","    combined_test_loader = DataLoader(combined_test_dataset, batch_size=batch_size, shuffle=False)\n","\n","    combined_model, combined_train_acc, combined_val_acc = train_model(\n","        \"combined\", combined_train_loader, combined_val_loader, device, static_features\n","    )\n","    combined_test_metrics = evaluate_model(combined_model, \"combined\", combined_test_loader, device, static_features)\n","    combined_test_acc = combined_test_metrics[0]  # Extract test accuracy\n","\n","    # 2. Ball-only model\n","    print(\"\\n=== Training Ball-Only Model ===\")\n","    ball_train_dataset = ShotDataset(ball_sequences=X_train_ball, static_features=None, labels=y_train)\n","    ball_val_dataset = ShotDataset(ball_sequences=X_val_ball, static_features=None, labels=y_val)\n","    ball_test_dataset = ShotDataset(ball_sequences=X_test_ball, static_features=None, labels=y_test)\n","\n","    ball_train_loader = DataLoader(ball_train_dataset, batch_size=batch_size, shuffle=True)\n","    ball_val_loader = DataLoader(ball_val_dataset, batch_size=batch_size, shuffle=False)\n","    ball_test_loader = DataLoader(ball_test_dataset, batch_size=batch_size, shuffle=False)\n","\n","    ball_model, ball_train_acc, ball_val_acc = train_model(\n","        \"ball_only\", ball_train_loader, ball_val_loader, device, static_features\n","    )\n","    ball_test_metrics = evaluate_model(ball_model, \"ball_only\", ball_test_loader, device, static_features)\n","    ball_test_acc = ball_test_metrics[0]  # Extract test accuracy\n","\n","    # 3. Static-only model\n","    print(\"\\n=== Training Static-Only Model ===\")\n","    static_train_dataset = ShotDataset(ball_sequences=None, static_features=X_train_static, labels=y_train)\n","    static_val_dataset = ShotDataset(ball_sequences=None, static_features=X_val_static, labels=y_val)\n","    static_test_dataset = ShotDataset(ball_sequences=None, static_features=X_test_static, labels=y_test)\n","\n","    static_train_loader = DataLoader(static_train_dataset, batch_size=batch_size, shuffle=True)\n","    static_val_loader = DataLoader(static_val_dataset, batch_size=batch_size, shuffle=False)\n","    static_test_loader = DataLoader(static_test_dataset, batch_size=batch_size, shuffle=False)\n","\n","    static_model, static_train_acc, static_val_acc = train_model(\n","        \"static_only\", static_train_loader, static_val_loader, device, static_features\n","    )\n","    static_test_metrics = evaluate_model(static_model, \"static_only\", static_test_loader, device, static_features)\n","    static_test_acc = static_test_metrics[0]  # Extract test accuracy\n","\n","    # Summary of results\n","    results = {\n","        \"Combined Model\": {\n","            \"Train Accuracy\": combined_train_acc,\n","            \"Validation Accuracy\": combined_val_acc,\n","            \"Test Accuracy\": combined_test_acc\n","        },\n","        \"Ball-Only Model\": {\n","            \"Train Accuracy\": ball_train_acc,\n","            \"Validation Accuracy\": ball_val_acc,\n","            \"Test Accuracy\": ball_test_acc\n","        },\n","        \"Static-Only Model\": {\n","            \"Train Accuracy\": static_train_acc,\n","            \"Validation Accuracy\": static_val_acc,\n","            \"Test Accuracy\": static_test_acc\n","        }\n","    }\n","\n","    # Print summary table\n","    print(\"\\n===== ABLATION STUDY RESULTS =====\")\n","    print(f\"{'Model':<20} {'Train Acc':<15} {'Val Acc':<15} {'Test Acc':<15}\")\n","    print(\"-\" * 65)\n","    for model_name, metrics in results.items():\n","        print(f\"{model_name:<20} {metrics['Train Accuracy']:<15.4f} {metrics['Validation Accuracy']:<15.4f} {metrics['Test Accuracy']:<15.4f}\")\n","\n","    # Save results to file\n","    with open(os.path.join(output_path, 'ablation_results.txt'), 'w') as f:\n","        f.write(\"===== ABLATION STUDY RESULTS =====\\n\")\n","        f.write(f\"{'Model':<20} {'Train Acc':<15} {'Val Acc':<15} {'Test Acc':<15}\\n\")\n","        f.write(\"-\" * 65 + \"\\n\")\n","        for model_name, metrics in results.items():\n","            f.write(f\"{model_name:<20} {metrics['Train Accuracy']:<15.4f} {metrics['Validation Accuracy']:<15.4f} {metrics['Test Accuracy']:<15.4f}\\n\")\n","\n","    # Create comparison bar plot\n","    plt.figure(figsize=(12, 8))\n","    models = list(results.keys())\n","    train_accs = [results[m][\"Train Accuracy\"] for m in models]\n","    val_accs = [results[m][\"Validation Accuracy\"] for m in models]\n","    test_accs = [results[m][\"Test Accuracy\"] for m in models]\n","\n","    x = np.arange(len(models))\n","    width = 0.25\n","\n","    plt.bar(x - width, train_accs, width, label='Train Accuracy')\n","    plt.bar(x, val_accs, width, label='Validation Accuracy')\n","    plt.bar(x + width, test_accs, width, label='Test Accuracy')\n","\n","    plt.xlabel('Models')\n","    plt.ylabel('Accuracy')\n","    plt.title('Comparison of Model Performance Across Ablation Studies')\n","    plt.xticks(x, models)\n","    plt.legend()\n","    plt.grid(axis='y', alpha=0.3)\n","\n","    plt.tight_layout()\n","    plt.savefig(os.path.join(output_path, 'ablation_comparison.png'))\n","    plt.close()\n","\n","    print(f\"Results saved to {output_path}\")\n","    return results"],"metadata":{"id":"-Gd-HA6VdIxT","executionInfo":{"status":"ok","timestamp":1746566519923,"user_tz":-330,"elapsed":10,"user":{"displayName":"Aarathi Baburaj","userId":"17090552282489356926"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","  run_ablation_study()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fceB7f7UZSU9","executionInfo":{"status":"ok","timestamp":1746566598625,"user_tz":-330,"elapsed":78702,"user":{"displayName":"Aarathi Baburaj","userId":"17090552282489356926"}},"outputId":"371b6a69-c989-4920-cfb3-27bff4c9cd63"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading datasets...\n","Extracting features...\n","Processing ball sequences...\n","\n","=== Training Combined Model (Baseline) ===\n","\n","=== Training Ball-Only Model ===\n","\n","=== Training Static-Only Model ===\n","\n","===== ABLATION STUDY RESULTS =====\n","Model                Train Acc       Val Acc         Test Acc       \n","-----------------------------------------------------------------\n","Combined Model       0.8132          0.8272          0.8217         \n","Ball-Only Model      0.7914          0.8281          0.7840         \n","Static-Only Model    0.7728          0.7658          0.7623         \n","Results saved to /content/drive/MyDrive/smai_project/output_ablation_study/\n"]}]}]}